{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "history_visible": true,
      "authorship_tag": "ABX9TyM0ij1nT6InAkJflMklhkvb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/q1170686276/AndroidReview/blob/master/Image_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using TensorFlow backend"
      ],
      "metadata": {
        "id": "lzJ9-k6g6s_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P8fE2IY76dna"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "sns.set(style='white', context='notebook', palette='deep')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial preparation"
      ],
      "metadata": {
        "id": "U8yMb71_6k99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from pylab import *\n",
        "import re\n",
        "from PIL import Image, ImageChops, ImageEnhance"
      ],
      "metadata": {
        "id": "TnP15VX56xjz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions"
      ],
      "metadata": {
        "id": "5FL7AV8n6rb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_imlist(path):\n",
        "  return [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.jpg') or f.endswith('.png')]"
      ],
      "metadata": {
        "id": "lqprGLo06124"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_ela_image(path,quality):\n",
        "  filename = path\n",
        "  resaved_filename = filename.split('.')[0] + '.resaved.jpg'\n",
        "  ELA_filename = filename.split('.')[0] + '.ela.png'\n",
        "\n",
        "  im = Image.open(filename).convert('RGB')\n",
        "  im.save(resaved_filename,'JPEG',quality=quality)\n",
        "  resaved_im = Image.open(resaved_filename)\n",
        "\n",
        "  ela_im = ImageChops.difference(im, resaved_im)\n",
        "\n",
        "  extrema = ela_im.getextrema()\n",
        "  max_diff = max({ex[1] for ex in extrema})\n",
        "  if max_diff == 0:\n",
        "    max_diff = 1\n",
        "  scale = 255.0 / max_diff\n",
        "\n",
        "  ela_im = ImageEnhance.brightness(ela_im).enhance(scale)\n",
        "    \n",
        "  return ela_im\n"
      ],
      "metadata": {
        "id": "qEemGdXL7cQy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample:Real Image"
      ],
      "metadata": {
        "id": "nLHK0MkE9VY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open('')\n",
        "\n",
        "convert_to_ela_image('',90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "RxskYdu17o3l",
        "outputId": "affc3e9f-002b-4241-ffad-6448d4b77420"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2846\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2847\u001b[0;31m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2848\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'seek'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-956f22ac9ab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconvert_to_ela_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2847\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample:Fake image"
      ],
      "metadata": {
        "id": "t6Lk6x3h90mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open('')\n",
        "\n",
        "convert_to_ela_image('')\n"
      ],
      "metadata": {
        "id": "wISqUeMscFoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparation\n",
        "\n",
        "Read dataset and conversion to ELA"
      ],
      "metadata": {
        "id": "QaYzyttWcTFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('')"
      ],
      "metadata": {
        "id": "IJ-oGc4Zcc_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []"
      ],
      "metadata": {
        "id": "pssEgsJ5cn0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in dataset.iterrows():\n",
        "    X.append(array(convert_to_ela_image(row[0],90),resize((128,128))).flatten() / 255.0)\n",
        "    Y.appedn(row[1])"
      ],
      "metadata": {
        "id": "40vT_oB4cwJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization"
      ],
      "metadata": {
        "id": "I-1wq6JndIlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.arry(X)\n",
        "Y = to_categorical(Y,2)"
      ],
      "metadata": {
        "id": "fkWQBU-hdKHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape X"
      ],
      "metadata": {
        "id": "oWnlC7HidRBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.reshape(-1,128,128,3)"
      ],
      "metadata": {
        "id": "SRcNiqMidT8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-test split"
      ],
      "metadata": {
        "id": "5JDX5wbadSqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_val,Y_train,Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)"
      ],
      "metadata": {
        "id": "wMy3PZBfdZi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "f-cvtKpadtbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32,kernel_size = (5,5),padding = 'valid',\n",
        "                 activation = 'relu', input_shape = (128,128,3)))\n",
        "print(\"Input:\",model.input_shape)\n",
        "print(\"Output\",model.output_shape)\n",
        "\n",
        "model.add(Conv2D(filters = 32,kernel_size = (5,5),padding = 'valid',\n",
        "                 activation = 'relu'))\n",
        "print(\"Input:\",model.input_shape)\n",
        "print(\"Output\",model.output_shape)\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "print(\"Input:\",model.input_shape)\n",
        "print(\"Output\",model.output_shape)\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2,activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "LbFuHd7advyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "FXJDO3i7hCyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add optimizer"
      ],
      "metadata": {
        "id": "z7v0UsUehIVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)"
      ],
      "metadata": {
        "id": "8pgc-QiShL15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "vmTNtVHciX7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define early stopping"
      ],
      "metadata": {
        "id": "Cdcw61n4i4x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_acc',\n",
        "                               min_delta=0,\n",
        "                               patience=2,\n",
        "                               verbose=0,mode='auto')"
      ],
      "metadata": {
        "id": "IRl7pkkPjBFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training"
      ],
      "metadata": {
        "id": "7ipdHDc2jVTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "batch_size = 100"
      ],
      "metadata": {
        "id": "G5KHayG2jXun"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,Y_train,batch_size, epochs =epochs,\n",
        "                    validation_data = (X_val,Y_val),verbose =2,callbacks=(early_stopping))"
      ],
      "metadata": {
        "id": "yfV8Z2lfjbvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prefprmace measure\n",
        "\n",
        "Accuracy and loss curves during training-validation"
      ],
      "metadata": {
        "id": "Ir3Ov2zOjwyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the loss. and accuracy curves for training and validation\n",
        "fig,ax = plt.subplots(2,1)\n",
        "ax[0].plot(history.history['loss'], color='b', label=\"training loss\")\n",
        "ax[0].plot(history.history['val_loss'],clolr='r', label=\"validation loss\",axes = ax[0])\n",
        "legend =ax[0].legend(loc='best',shadow=True)\n",
        "\n",
        "ax[1].plot(history.history['loss'], color='b', label=\"training loss\")\n",
        "ax[1].plot(history.history['val_loss'],clolr='r', label=\"validation loss\")\n",
        "legend =ax[1].legend(loc='best',shadow=True)"
      ],
      "metadata": {
        "id": "KP7Tng1fj3-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix"
      ],
      "metadata": {
        "id": "MWYgO5_SmnZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation = 'nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "      cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
        "\n",
        "    thresh =cm.max()/1\n",
        "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "      plt.text(j,i,cm[i,j],\n",
        "               horizontalaignment=\"center\",\n",
        "               color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "      \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('preditcted label')\n",
        "  \n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(X_val)\n",
        "# Convert predictions classes to one hot vectors \n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(Y_val,axis = 1) \n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(2))\n"
      ],
      "metadata": {
        "id": "mCNlY01amqMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}